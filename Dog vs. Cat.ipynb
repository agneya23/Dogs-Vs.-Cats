{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Dog vs. Cat.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPvEil5my8ugJgjvwa909ZR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d6977ff8a63d4553b8b07695a17c17ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3e3ba11b04a84e2a8ee7742b3ed07b06","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a64bf0c1fc4141529ced559194b42b18","IPY_MODEL_0aeb2dd250a747afaede270121761ad9"]}},"3e3ba11b04a84e2a8ee7742b3ed07b06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a64bf0c1fc4141529ced559194b42b18":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_99eb25d9a3814dc7a18cf08d239fa4e8","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":46830571,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":46830571,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1abb4ca5a7a24bae8736a9aacc34cb22"}},"0aeb2dd250a747afaede270121761ad9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cc037c717f434cc7bc099c353aa0b65c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 44.7M/44.7M [23:22&lt;00:00, 33.4kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_44e9b07426a742dfb4c3b913e8df164d"}},"99eb25d9a3814dc7a18cf08d239fa4e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1abb4ca5a7a24bae8736a9aacc34cb22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cc037c717f434cc7bc099c353aa0b65c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"44e9b07426a742dfb4c3b913e8df164d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"DiYkccLjq0fr"},"source":["Dog vs. Cat Image Classifier. \n","\n","Methods:-\n","1. Fully Connected Neural Network\n","2. CNN\n","3. Transfer Learning"]},{"cell_type":"code","metadata":{"id":"ixYkT1NXo-dL","executionInfo":{"status":"ok","timestamp":1626455668381,"user_tz":-330,"elapsed":4829,"user":{"displayName":"AGNEYA BHARDWAJ","photoUrl":"","userId":"00265966098106311489"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import copy\n","import torch\n","import torch.nn as nn\n","from torchvision.io import read_image\n","from torchvision import datasets, models, transforms\n","\n","%matplotlib inline"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"LQ2TP1jcvwuR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626455697390,"user_tz":-330,"elapsed":26465,"user":{"displayName":"AGNEYA BHARDWAJ","photoUrl":"","userId":"00265966098106311489"}},"outputId":"410b68a0-662f-448a-e4a8-0f5fb7555820"},"source":["# Mount the drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"flJpNgV6R5OX","executionInfo":{"status":"ok","timestamp":1626457142889,"user_tz":-330,"elapsed":480,"user":{"displayName":"AGNEYA BHARDWAJ","photoUrl":"","userId":"00265966098106311489"}}},"source":["# Prepare dataset\n","dir1 = r'/content/drive/MyDrive/Projects (Self)/Dog vs. Cat/data/train'\n","dir2 = r'/content/drive/MyDrive/Projects (Self)/Dog vs. Cat/data/val'\n","dir3 = r'/content/drive/MyDrive/Projects (Self)/Dog vs. Cat/data/test'\n","\n","transform = transforms.Compose([transforms.Resize([96, 96]), transforms.ToTensor(), \n","                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","train = datasets.ImageFolder(root=dir1, transform=transform) # 1600\n","val = datasets.ImageFolder(root=dir2, transform=transform) # 300\n","test = datasets.ImageFolder(root=dir3, transform=transform) # 100"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"MUM6S_vkTei4","executionInfo":{"status":"ok","timestamp":1626457147017,"user_tz":-330,"elapsed":764,"user":{"displayName":"AGNEYA BHARDWAJ","photoUrl":"","userId":"00265966098106311489"}}},"source":["# Create dataloaders\n","train_loader = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True) # 50 batches\n","val_loader = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True) # 30 batches\n","test_loader = torch.utils.data.DataLoader(train, batch_size=100, shuffle=True) # 1 batch"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DodQ-SkUhWUI"},"source":["## Fully Connected Neural Network"]},{"cell_type":"code","metadata":{"id":"jGN0S6fs0hQH","executionInfo":{"status":"ok","timestamp":1626457441316,"user_tz":-330,"elapsed":778,"user":{"displayName":"AGNEYA BHARDWAJ","photoUrl":"","userId":"00265966098106311489"}}},"source":["# Create a sequential model (3 hidden layers)\n","model = nn.Sequential(nn.Linear(3 * 96 * 96, 24),\n","                      nn.ReLU(),\n","                      nn.Linear(24, 12),\n","                      nn.ReLU(),\n","                      nn.Linear(12, 6),\n","                      nn.ReLU(),\n","                      nn.Linear(6, 2),\n","                      nn.Softmax(dim=1))\n","\n","# Define loss and optimizer\n","loss = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.05)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z1R6UZgNl6aC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626457757033,"user_tz":-330,"elapsed":261044,"user":{"displayName":"AGNEYA BHARDWAJ","photoUrl":"","userId":"00265966098106311489"}},"outputId":"ab904ecf-1f4d-426e-dbec-ba001bea945d"},"source":["# Train the model on the data \n","best_val_loss = float('inf')\n","best_model_wts = copy.deepcopy(model.state_dict())\n","num_epoch = 15\n","for i in range(num_epoch):\n","    total_train_loss, total_val_loss, train_loss, val_loss = 0, 0, 0, 0\n","    for train_images, train_labels in train_loader:\n","        # Flatten Images\n","        train_images = train_images.view(train_images.shape[0], -1)\n","        train_pred_prob = model(train_images)     \n","        train_loss = loss(train_pred_prob, train_labels)\n","        optimizer.zero_grad()\n","        train_loss.backward(retain_graph=True)\n","        optimizer.step()\n","        total_train_loss += train_loss\n","    total_train_loss /= len(train)\n","\n","    for val_images, val_labels in val_loader:\n","        # Flatten Images\n","        val_images = val_images.view(val_images.shape[0], -1)\n","        val_pred_prob = model(val_images)\n","        val_loss = loss(val_pred_prob, val_labels)\n","        total_val_loss += val_loss\n","    total_val_loss /= len(val)\n","    \n","    print(\"The value of train loss at epoch {} is: {}\".format(i+1, total_train_loss))\n","    print(\"The value of val loss at epoch {} is: {}\".format(i+1, total_val_loss))\n","    print()\n","\n","    if total_val_loss < best_val_loss:\n","        best_val_loss = total_val_loss\n","        best_model_wts = copy.deepcopy(model.state_dict())\n","\n","print(\"The best val loss achieved is: {}\".format(best_val_loss))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["The value of train loss at epoch 1 is: 0.020256146788597107\n","The value of val loss at epoch 1 is: 0.3331693410873413\n","\n","The value of train loss at epoch 2 is: 0.01960798352956772\n","The value of val loss at epoch 2 is: 0.32544469833374023\n","\n","The value of train loss at epoch 3 is: 0.01875516027212143\n","The value of val loss at epoch 3 is: 0.3159807622432709\n","\n","The value of train loss at epoch 4 is: 0.018143992871046066\n","The value of val loss at epoch 4 is: 0.2914224863052368\n","\n","The value of train loss at epoch 5 is: 0.017607230693101883\n","The value of val loss at epoch 5 is: 0.2812132239341736\n","\n","The value of train loss at epoch 6 is: 0.016959115862846375\n","The value of val loss at epoch 6 is: 0.2601413130760193\n","\n","The value of train loss at epoch 7 is: 0.016231916844844818\n","The value of val loss at epoch 7 is: 0.2573521137237549\n","\n","The value of train loss at epoch 8 is: 0.01576978527009487\n","The value of val loss at epoch 8 is: 0.2494174689054489\n","\n","The value of train loss at epoch 9 is: 0.01531133335083723\n","The value of val loss at epoch 9 is: 0.2555038332939148\n","\n","The value of train loss at epoch 10 is: 0.01491183415055275\n","The value of val loss at epoch 10 is: 0.2320450097322464\n","\n","The value of train loss at epoch 11 is: 0.01427965797483921\n","The value of val loss at epoch 11 is: 0.2387266755104065\n","\n","The value of train loss at epoch 12 is: 0.014047530479729176\n","The value of val loss at epoch 12 is: 0.22794248163700104\n","\n","The value of train loss at epoch 13 is: 0.013712164014577866\n","The value of val loss at epoch 13 is: 0.2393515706062317\n","\n","The value of train loss at epoch 14 is: 0.01377588789910078\n","The value of val loss at epoch 14 is: 0.21271847188472748\n","\n","The value of train loss at epoch 15 is: 0.013163911178708076\n","The value of val loss at epoch 15 is: 0.21275737881660461\n","\n","The best val loss achieved is: 0.21271847188472748\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h5sBfFqml3dn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626457782851,"user_tz":-330,"elapsed":8974,"user":{"displayName":"AGNEYA BHARDWAJ","photoUrl":"","userId":"00265966098106311489"}},"outputId":"7f65ee06-3360-465c-bbb4-0a0d0c3832bd"},"source":["model.load_state_dict(best_model_wts)\n","# Make predictions on test data\n","for test_images, test_labels in test_loader:\n","    test_images = test_images.view(test_images.shape[0], -1)\n","    test_pred_prob = model(test_images)\n","    test_y_pred = test_pred_prob.argmax(1)\n","    test_acc = ((test_labels == test_y_pred)*1.0).mean() * 100 # Measure accuracy on test data\n","print(\"The accuracy achieved on the test data is: {}%\".format(test_acc))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["The accuracy achieved on the test data is: 92.0%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Er0eEEdumYHd"},"source":["## CNN"]},{"cell_type":"code","metadata":{"id":"GJxJnQa6oMn_","executionInfo":{"status":"ok","timestamp":1626458837937,"user_tz":-330,"elapsed":1133,"user":{"displayName":"AGNEYA BHARDWAJ","photoUrl":"","userId":"00265966098106311489"}}},"source":["# Create a sequential model (3 hidden layers)\n","cnn = nn.Sequential(nn.Conv2d(3, 18, 4, 2, padding='valid'),  # out_channels=no. of filters, kernel_size=filter size\n","                    nn.ReLU(),\n","                    nn.Conv2d(18, 36, 4, 2, padding='valid'),\n","                    nn.MaxPool2d(4))\n","\n","linear = nn.Sequential(nn.Linear(900, 24),   # changed from 250 to 900, check why.\n","                       nn.ReLU(),\n","                       nn.Linear(24, 2),\n","                       nn.Softmax(dim=1))\n","\n","# Define loss and optimizer\n","loss = nn.CrossEntropyLoss()\n","optimizer_cnn = torch.optim.SGD(cnn.parameters(), lr=0.18)\n","optimizer_linear = torch.optim.SGD(linear.parameters(), lr=0.18)"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"SNfPqtczoMbo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626459161546,"user_tz":-330,"elapsed":323071,"user":{"displayName":"AGNEYA BHARDWAJ","photoUrl":"","userId":"00265966098106311489"}},"outputId":"b4bbabb2-1170-4d17-9ef0-952729bdd0d8"},"source":["# Train the model on the data \n","best_val_loss = float('inf')\n","best_cnn_wts = copy.deepcopy(cnn.state_dict())\n","best_linear_wts = copy.deepcopy(linear.state_dict())\n","num_epoch = 15\n","for i in range(num_epoch):\n","    total_train_loss, total_val_loss, train_loss, val_loss = 0, 0, 0, 0\n","    for train_images, train_labels in train_loader:\n","        out_cnn = cnn(train_images)    \n","        out_cnn = out_cnn.reshape(out_cnn.shape[0], -1) \n","        train_pred_prob = linear(out_cnn)\n","        train_loss = loss(train_pred_prob, train_labels)\n","        optimizer_cnn.zero_grad()\n","        optimizer_linear.zero_grad()\n","        train_loss.backward(retain_graph=True)\n","        optimizer_cnn.step()\n","        optimizer_linear.step()\n","        total_train_loss += train_loss\n","    total_train_loss /= len(train)\n","\n","    for val_images, val_labels in val_loader:\n","        out_linear = cnn(val_images)\n","        out_linear = out_linear.reshape(out_linear.shape[0], -1)\n","        val_pred_prob = linear(out_linear)\n","        val_loss = loss(val_pred_prob, val_labels)\n","        total_val_loss += val_loss\n","    total_val_loss /= len(val)\n","   \n","    print(\"The value of train loss at epoch {} is: {}\".format(i+1, total_train_loss))\n","    print(\"The value of val loss at epoch {} is: {}\".format(i+1, total_val_loss))\n","    print()\n","\n","    if total_val_loss < best_val_loss:\n","        best_val_loss = total_val_loss\n","        best_cnn_wts = copy.deepcopy(cnn.state_dict())\n","        best_linear_wts = copy.deepcopy(linear.state_dict())\n","\n","print(\"The best val loss achieved is: {}\".format(best_val_loss))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["The value of train loss at epoch 1 is: 0.02166030928492546\n","The value of val loss at epoch 1 is: 0.36872220039367676\n","\n","The value of train loss at epoch 2 is: 0.02158530056476593\n","The value of val loss at epoch 2 is: 0.36632752418518066\n","\n","The value of train loss at epoch 3 is: 0.021323544904589653\n","The value of val loss at epoch 3 is: 0.35675695538520813\n","\n","The value of train loss at epoch 4 is: 0.020864540711045265\n","The value of val loss at epoch 4 is: 0.3440302908420563\n","\n","The value of train loss at epoch 5 is: 0.020128043368458748\n","The value of val loss at epoch 5 is: 0.32871758937835693\n","\n","The value of train loss at epoch 6 is: 0.0194637980312109\n","The value of val loss at epoch 6 is: 0.3676465153694153\n","\n","The value of train loss at epoch 7 is: 0.01931377686560154\n","The value of val loss at epoch 7 is: 0.3305133879184723\n","\n","The value of train loss at epoch 8 is: 0.018972836434841156\n","The value of val loss at epoch 8 is: 0.3112010359764099\n","\n","The value of train loss at epoch 9 is: 0.018446894362568855\n","The value of val loss at epoch 9 is: 0.29452213644981384\n","\n","The value of train loss at epoch 10 is: 0.018031954765319824\n","The value of val loss at epoch 10 is: 0.28806203603744507\n","\n","The value of train loss at epoch 11 is: 0.017364956438541412\n","The value of val loss at epoch 11 is: 0.30602186918258667\n","\n","The value of train loss at epoch 12 is: 0.01699570007622242\n","The value of val loss at epoch 12 is: 0.2729298174381256\n","\n","The value of train loss at epoch 13 is: 0.016488516703248024\n","The value of val loss at epoch 13 is: 0.2694719731807709\n","\n","The value of train loss at epoch 14 is: 0.016310518607497215\n","The value of val loss at epoch 14 is: 0.265654981136322\n","\n","The value of train loss at epoch 15 is: 0.01578162983059883\n","The value of val loss at epoch 15 is: 0.2562468349933624\n","\n","The best val loss achieved is: 0.2562468349933624\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mLwgOfl1ockY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626459175960,"user_tz":-330,"elapsed":10354,"user":{"displayName":"AGNEYA BHARDWAJ","photoUrl":"","userId":"00265966098106311489"}},"outputId":"13af32c2-21de-4fe2-b415-6d13ac99570f"},"source":["cnn.load_state_dict(best_cnn_wts)\n","linear.load_state_dict(best_linear_wts)\n","# Make predictions on test data\n","for test_images, test_labels in test_loader:\n","    out = cnn(test_images)\n","    out = out.reshape(out.shape[0], -1)\n","    test_pred_prob = linear(out)\n","    test_y_pred = test_pred_prob.argmax(1)\n","    test_acc = ((test_labels == test_y_pred)*1.0).mean() * 100 # Measure accuracy on test data\n","print(\"The accuracy achieved on the test data is: {}%\".format(test_acc))"],"execution_count":34,"outputs":[{"output_type":"stream","text":["The accuracy achieved on the test data is: 84.0%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AjS7zngNoUFz"},"source":["## Transfer Learning"]},{"cell_type":"code","metadata":{"id":"_z3iJficoayp","colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["d6977ff8a63d4553b8b07695a17c17ce","3e3ba11b04a84e2a8ee7742b3ed07b06","a64bf0c1fc4141529ced559194b42b18","0aeb2dd250a747afaede270121761ad9","99eb25d9a3814dc7a18cf08d239fa4e8","1abb4ca5a7a24bae8736a9aacc34cb22","cc037c717f434cc7bc099c353aa0b65c","44e9b07426a742dfb4c3b913e8df164d"]},"executionInfo":{"status":"ok","timestamp":1626459210049,"user_tz":-330,"elapsed":1943,"user":{"displayName":"AGNEYA BHARDWAJ","photoUrl":"","userId":"00265966098106311489"}},"outputId":"255ae621-b6e2-45f5-8514-205a09094de3"},"source":["dir1 = r'/content/drive/MyDrive/Projects (Self)/Dog vs. Cat/data/train'\n","dir2 = r'/content/drive/MyDrive/Projects (Self)/Dog vs. Cat/data/val'\n","dir3 = r'/content/drive/MyDrive/Projects (Self)/Dog vs. Cat/data/test'\n","\n","# Images ought to be normalized as per the requirements of the pre-trained model\n","transform = transforms.Compose([transforms.Resize([224, 224]), transforms.ToTensor(), \n","                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n","\n","train = datasets.ImageFolder(root=dir1, transform=transform) # 1600\n","val = datasets.ImageFolder(root=dir2, transform=transform) # 300\n","test = datasets.ImageFolder(root=dir3, transform=transform) # 100\n","\n","# Create dataloaders\n","train_loader = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True) # 50 batches\n","val_loader = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True) # 30 batches\n","test_loader = torch.utils.data.DataLoader(train, batch_size=100, shuffle=True) # 1 batch\n","\n","# Create model\n","resnet_18 = models.resnet18(pretrained=True)\n","# Set gradient equal to zero for earlier layers such that only final layer parameters are learned (Feature Extraction)\n","for param in resnet_18.parameters():\n","    param.requires_grad = False\n","resnet_18.fc = nn.Linear(512, 2)\n","\n","# Define loss and optimizer\n","loss = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(resnet_18.parameters(), lr=0.1)\n","softmax = nn.Softmax(dim=1)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d6977ff8a63d4553b8b07695a17c17ce","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=46830571.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t2n8RC2FoamU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626460610502,"user_tz":-330,"elapsed":1388011,"user":{"displayName":"AGNEYA BHARDWAJ","photoUrl":"","userId":"00265966098106311489"}},"outputId":"b1654ade-6cca-4c1b-9aab-85970a1ee88b"},"source":["# Perform feature extraction \n","resnet_18.train()\n","best_val_loss = float('inf')\n","best_model_wts = copy.deepcopy(resnet_18.state_dict())\n","num_epoch = 5\n","for i in range(num_epoch):\n","    total_train_loss, total_val_loss, train_loss, val_loss = 0, 0, 0, 0\n","    for train_images, train_labels in train_loader:\n","        train_pred_prob = resnet_18(train_images)     \n","        train_loss = loss(train_pred_prob, train_labels)\n","        optimizer.zero_grad()\n","        train_loss.backward(retain_graph=True)\n","        optimizer.step()\n","        total_train_loss += train_loss\n","    total_train_loss /= len(train)\n","\n","    for val_images, val_labels in val_loader:\n","        val_pred_prob = resnet_18(val_images)\n","        val_loss = loss(val_pred_prob, val_labels)\n","        total_val_loss += val_loss\n","    total_val_loss /= len(val)\n","            \n","    print(\"The value of train loss at epoch {} is: {}\".format(i+1, total_train_loss))\n","    print(\"The value of val loss at epoch {} is: {}\".format(i+1, total_val_loss))\n","    print()\n","\n","    if total_val_loss < best_val_loss:\n","        best_val_loss = total_val_loss\n","        best_model_wts = copy.deepcopy(resnet_18.state_dict())\n","\n","print(\"The best val loss achieved is: {}\".format(best_val_loss))"],"execution_count":36,"outputs":[{"output_type":"stream","text":["The value of train loss at epoch 1 is: 0.030910074710845947\n","The value of val loss at epoch 1 is: 0.15487460792064667\n","\n","The value of train loss at epoch 2 is: 0.0065624606795609\n","The value of val loss at epoch 2 is: 0.26391637325286865\n","\n","The value of train loss at epoch 3 is: 0.005241422448307276\n","The value of val loss at epoch 3 is: 0.19746126234531403\n","\n","The value of train loss at epoch 4 is: 0.006290162913501263\n","The value of val loss at epoch 4 is: 0.13073702156543732\n","\n","The value of train loss at epoch 5 is: 0.004361941013485193\n","The value of val loss at epoch 5 is: 0.2406197339296341\n","\n","The best val loss achieved is: 0.13073702156543732\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DD10NZduoaBi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626460819637,"user_tz":-330,"elapsed":131731,"user":{"displayName":"AGNEYA BHARDWAJ","photoUrl":"","userId":"00265966098106311489"}},"outputId":"9097a8de-e1bb-43c1-8f6b-37e6af293f0f"},"source":["resnet_18.load_state_dict(best_model_wts)\n","resnet_18.eval()\n","# Make predictions on test data\n","for test_images, test_labels in test_loader:\n","    test_pred_prob = softmax.forward(resnet_18(test_images))\n","    test_y_pred = test_pred_prob.argmax(1)\n","test_acc = ((test_labels == test_y_pred)*1.0).mean() * 100 # Measure accuracy on test data\n","print(\"The accuracy achieved on the test data is: {}%\".format(test_acc))"],"execution_count":37,"outputs":[{"output_type":"stream","text":["The accuracy achieved on the test data is: 98.0%\n"],"name":"stdout"}]}]}